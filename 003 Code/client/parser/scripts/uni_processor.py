import os
import sys
import json
import fitz
import argparse
import base64 # ğŸ‘ˆ [ì¶”ê°€] Base64 ì¸ì½”ë”©ì„ ìœ„í•´ ì¶”ê°€
from pathlib import Path

# í”„ë¡œì íŠ¸ root path ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from pdf_processor.core.extractor import PDFExtractor
from pdf_processor.utils.file_utils import FileUtils

def log_to_stderr(*args, **kwargs):
    print(*args, file=sys.stderr, **kwargs)

# ğŸ”½ [ì¶”ê°€] ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì–´ Base64ë¡œ ì¸ì½”ë”©í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
def encode_image_to_base64(image_path):
    """
    ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ Base64 ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not os.path.exists(image_path):
        log_to_stderr(f"Warning: Image file not found at {image_path}")
        return None
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except Exception as e:
        log_to_stderr(f"Error encoding image {image_path}: {e}")
        return None

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Process PDF files and extract content")
    
    parser.add_argument("--input-files", required=True, nargs='+', help="List of input PDF files")
    parser.add_argument("--original-stems", required=True, nargs='+', help="List of original PDF file stems")
    
    parser.add_argument("--output-dir", required=True, help="Temporary output directory")
    
    parser.add_argument("--chunk-size", type=int, default=1024)
    parser.add_argument("--dpi", type=int, default=300)
    parser.add_argument("--overlap-threshold", type=float, default=0.7)
    args = parser.parse_args()

    if len(args.input_files) != len(args.original_stems):
        log_to_stderr(f"Error: Mismatch count --input-files ({len(args.input_files)}) vs --original-stems ({len(args.original_stems)})")
        sys.exit(1)

    FileUtils.ensure_directory(args.output_dir)

    processor = PDFExtractor(
        chunk_size=args.chunk_size,
        dpi=args.dpi,
        overlap_threshold=args.overlap_threshold
    )

    all_text_chunks = []
    all_image_chunks = []
    results_list = []
    
    all_successful = True 

    for pdf_file, original_stem in zip(args.input_files, args.original_stems):
        base_pdf_name = os.path.basename(pdf_file)

        if not os.path.exists(pdf_file):
            log_to_stderr(f"File not found, skipping: {pdf_file}")
            results_list.append({"baseName": base_pdf_name, "status": "error", "message": "File not found"})
            all_successful = False
            continue

        log_to_stderr(f"Processing: {pdf_file} (as {original_stem})")
        
        page_count = 0
        try:
            with fitz.open(pdf_file) as doc:
                page_count = doc.page_count

            pdf_output_dir = os.path.join(args.output_dir, original_stem)
            FileUtils.ensure_directory(pdf_output_dir)

            all_chunks_list_raw = processor.extract_content(
                pdf_path=pdf_file,
                output_dir=pdf_output_dir
            )

            # ğŸ”½ [ìˆ˜ì •] Extractorì˜ ë°˜í™˜ê°’ì„ ë‹¨ì¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ê·œí™”
            content_list_raw = []
            if isinstance(all_chunks_list_raw, tuple) and len(all_chunks_list_raw) == 2:
                content_list_raw.extend(all_chunks_list_raw[0])
                content_list_raw.extend(all_chunks_list_raw[1])
            elif isinstance(all_chunks_list_raw, list):
                content_list_raw = all_chunks_list_raw
            else:
                raise ValueError(f"Extractor returned unexpected type: {type(all_chunks_list_raw)}. Expected tuple or list.")

            # 1. [ìˆ˜ì •] "í˜„ì¬ ê¸°ëŠ¥" ìœ ì§€: *í¬ë§·íŒ… ì „*ì— í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¡œ ë¶„ë¦¬
            text_content_list = []
            image_content_list = []
            
            # ğŸ”½ [ì œê±°] ë””ë²„ê¹… ë¡œê·¸ ì œê±°
            # log_to_stderr(f"--- Debugging chunks for {original_stem} (Total: {len(content_list_raw)}) ---")
            
            for i, chunk in enumerate(content_list_raw):
                # ğŸ”½ [ì œê±°] ë””ë²„ê¹… ë¡œê·¸ ì œê±°
                # chunk_keys = list(chunk.keys()) if isinstance(chunk, dict) else f"Not a dict: {type(chunk)}"
                # log_to_stderr(f"Chunk {i} Keys: {chunk_keys}")

                # ğŸ”½ [ìˆ˜ì •] ì´ë¯¸ì§€ ì‹ë³„ ë¡œì§ì„ "image_path" í‚¤ ì¡´ì¬ ì—¬ë¶€ë¡œ ë³€ê²½
                is_image = "image_path" in chunk
                
                if is_image:
                    image_content_list.append(chunk)
                else:
                    text_content_list.append(chunk)
            
            # ğŸ”½ [ì œê±°] ë””ë²„ê¹… ë¡œê·¸ ì œê±°
            # log_to_stderr(f"--- Debugging finished (Found {len(image_content_list)} images) ---")

            # 2. [ìˆ˜ì •] "ê¸°ì¡´ ì½”ë“œ" ë¡œì§: *í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸*ë§Œ í¬ë§·í„°ì— ì „ë‹¬
            formatted_text = processor.formatter.format_for_jsonl(text_content_list, original_stem)
            
            # (ë³€ê²½ ì—†ìŒ) "pdfName" (source) NULL ì˜¤ë¥˜ ë°©ì–´ ì½”ë“œ
            for chunk in formatted_text:
                if not chunk.get("source"): 
                    log_to_stderr(f"Warning: Chunk found with missing 'source'. Manually setting to '{original_stem}'.")
                    chunk["source"] = original_stem

            all_text_chunks.extend(formatted_text)

            # 3. [ìˆ˜ì •] "í˜„ì¬ ê¸°ëŠ¥" ìœ ì§€: *ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸*ëŠ” ìˆ˜ë™ìœ¼ë¡œ í¬ë§·íŒ…
            formatted_images = []
            for img_chunk in image_content_list:
                # ğŸ”½ [ìˆ˜ì •] ì´ë¯¸ì§€ ì²­í¬ì—ì„œ 'path' (ë˜ëŠ” 'src', 'image_path') í‚¤ë¥¼ ì°¾ì•„ Base64ë¡œ ì¸ì½”ë”©
                image_path = img_chunk.get("image_path", img_chunk.get("path", img_chunk.get("src")))
                base64_data = None

                if image_path:
                    # 'path'ê°€ output_dirì„ ê¸°ì¤€ìœ¼ë¡œ í•˜ëŠ”ì§€, ì ˆëŒ€ ê²½ë¡œì¸ì§€ í™•ì¸
                    if not os.path.isabs(image_path):
                        # ğŸ”½ [ìˆ˜ì •] ì¤‘ë³µ ê²½ë¡œ(stem/stem) ë²„ê·¸ ìˆ˜ì •
                        # Extractorê°€ ë°˜í™˜í•œ ê²½ë¡œëŠ” 'output_dir' ê¸°ì¤€ (ì˜ˆ: 'stem/image.png')
                        image_path = os.path.join(args.output_dir, image_path)
                    base64_data = encode_image_to_base64(image_path)
                else:
                    log_to_stderr(f"Warning: Image chunk found without 'image_path' key for {original_stem}.")
                
                formatted_images.append({
                    "source": original_stem, # ì´ë¯¸ì§€ì—ë„ 'source' ì„¤ì •
                    "data_base64": base64_data, # ğŸ‘ˆ Base64 ë°ì´í„°
                    "metadata": img_chunk.get("metadata", {})
                })
            all_image_chunks.extend(formatted_images)

            log_to_stderr(f"Successfully processed: {pdf_file} (Text: {len(formatted_text)}, Images: {len(formatted_images)})")
            
            results_list.append({
                "baseName": base_pdf_name,
                "originalStem": original_stem,
                "status": "success",
                "pageCount": page_count,
                "textChunkCount": len(formatted_text),
                "imageChunkCount": len(formatted_images)
            })

        except Exception as e:
            log_to_stderr(f"Error processing {pdf_file}: {e}")
            results_list.append({"baseName": base_pdf_name, "status": "error", "message": str(e), "pageCount": page_count})
            all_successful = False
            continue
    
    final_output = {
        "summary": results_list,
        "text_chunks": all_text_chunks,
        "image_chunks": all_image_chunks
    }
    
    print(json.dumps(final_output))

    if not all_successful:
        log_to_stderr("One or more files failed to process.")
        sys.exit(1)

    # try:
    #     output_json_path = Path(args.output_dir) / "uni_processor_output.json"
    #     with open(output_json_path, "w", encoding="utf-8") as f:
    #         json.dump(final_output, f, ensure_ascii=False, indent=2)
    #     log_to_stderr(f"Saved final_output JSON to: {output_json_path}")
    # except Exception as e:
    #     log_to_stderr(f"Error saving final_output JSON: {e}")

